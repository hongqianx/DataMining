{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from common.helpers import logger, has_nvidia_gpu, display_feature_importances\n",
    "from common.feature_engineering import feature_engineering\n",
    "from common.imputation import get_imputation_values, apply_imputation"
   ],
   "id": "2a1983a27dcc1c67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Configuration ---\n",
    "HAS_GPU = False # has_nvidia_gpu() # False #HAS_GPU = cp.cuda.runtime.getDeviceCount() > 0\n",
    "FOLD_AMOUNT = 3\n",
    "TESTSPLIT_RATIO = 10 # Percentage of data to be used for testing\n",
    "OPTUNA_TRIALS = 2 #20 # Number of trials for hyperparameter optimization\n",
    "ENSEMBLE_N_ESTIMATORS = 2 #50 # Number of estimators for the final stacking model\n",
    "TRAIN_WITHOUT_EVALUATION = False # If we should train without evaluation, gives more training data but can't output evaluation metrics\n",
    "TRAIN_DATA_PERCENTAGE = 0.01 # Percentage of train data to use for the training, 1 for everything (100%).\n",
    "TEST_DATA_PERCENTAGE = 0.01 # Percentage of test data to use for the training, 1 for everything (100%).\n",
    "categorical_feature = ['site_id', 'visitor_location_country_id', 'prop_country_id','month','dayofweek']"
   ],
   "id": "3e0914550ec11bc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Load the data ---\n",
    "training_data_path = r\"../input/training_set_VU_DM.csv\"\n",
    "test_data_path = r\"../input/test_set_VU_DM.csv\"\n",
    "# df = pd.read_csv(training_data_path).sample(frac=TRAIN_DATA_PERCENTAGE, random_state=42)\n",
    "# df_test = pd.read_csv(test_data_path).sample(frac=TEST_DATA_PERCENTAGE, random_state=42)\n",
    "df = pd.read_csv(training_data_path)\n",
    "df_test = pd.read_csv(test_data_path)"
   ],
   "id": "cbead37fbe681025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    mask = (data[column].between(lower_bound, upper_bound)) | (data[column].isna())\n",
    "    data_cleaned = data[mask].copy()\n",
    "    return data_cleaned"
   ],
   "id": "612c33ea7d06e381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_diff_from_group_mean(data, group_col='srch_id',value_col='prop_starrating'):\n",
    "    data_tmp = data.copy()\n",
    "    mean_col_name = f'{value_col}_mean_by_{group_col}'\n",
    "    data_tmp[mean_col_name] = data_tmp.groupby(group_col)[value_col].transform('mean')\n",
    "\n",
    "    diff_col_name = f'{value_col}_diff_from_mean'\n",
    "    data_tmp[diff_col_name] = data_tmp[value_col] - data_tmp[mean_col_name]\n",
    "    return data_tmp"
   ],
   "id": "4b8820b96c630221"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_book_feature(data):\n",
    "    conditions = [\n",
    "        data['booking_bool'] == 1,\n",
    "        data['click_bool'] == 1\n",
    "    ]\n",
    "\n",
    "    choices = [2, 1]\n",
    "\n",
    "    data['book_feature'] = np.select(conditions, choices, default=0)\n",
    "    data.drop(columns=['booking_bool', 'click_bool'], inplace=True, errors='ignore')\n",
    "    return data"
   ],
   "id": "400685c8811a796d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MAX_PRICE_NIGHT = 150000\n",
    "\n",
    "# Generate additional features that may be useful for the model\n",
    "def feature_engineering(data, type='train'):\n",
    "    logger.debug(\"Running feature engineering\")\n",
    "\n",
    "    # Delete rows gross_bookings_usd is significantly different from price_usd\n",
    "    if type=='train':\n",
    "        data['booking_price_diff'] = data['gross_bookings_usd'] - data['price_usd']\n",
    "        data = remove_outliers_iqr(data=data, column='booking_price_diff')\n",
    "        data.drop(columns=[\"booking_price_diff\"], inplace=True)\n",
    "\n",
    "    # transfer date to month and day of week\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'], errors='coerce')\n",
    "    data['month'] = data['date_time'].dt.month\n",
    "    data['dayofweek'] = data['date_time'].dt.dayofweek\n",
    "    data.drop(columns=[\"date_time\"], inplace=True)\n",
    "\n",
    "    # Feature for total number of adults and children\n",
    "    data[\"total_people\"] = data[\"srch_adults_count\"] + data[\"srch_children_count\"]\n",
    "\n",
    "    # History differences\n",
    "    data[\"history_starrating_diff\"] = data[\"visitor_hist_starrating\"] - data[\"prop_starrating\"]\n",
    "\n",
    "    # Total price per night per room\n",
    "    data['price_1room_1night'] = (data['price_usd'] / data['srch_room_count']) / data['srch_length_of_stay']\n",
    "    data[\"history_adr_diff\"] = data[\"visitor_hist_adr_usd\"] - data[\"price_1room_1night\"]\n",
    "\n",
    "    # Filter out high prices only for train data\n",
    "    if type=='train':\n",
    "        data = data[data['price_1room_1night'] < MAX_PRICE_NIGHT].copy()\n",
    "\n",
    "    # log transform\n",
    "    data['price_1room_1night_log'] = np.log1p(data['price_1room_1night'])\n",
    "    data[\"price_history_difference\"] = data[\"prop_log_historical_price\"] - data[\"price_1room_1night_log\"]\n",
    "    data['price_1person_1night'] = (data['price_usd'] / data['total_people']) / data['srch_length_of_stay']\n",
    "    data['price_1person_1night_log'] = np.log1p(data['price_1person_1night'])\n",
    "    data.drop(columns=['price_1room_1night'], inplace=True)\n",
    "    data.drop(columns=['price_1person_1night'], inplace=True)\n",
    "\n",
    "    # log transform price, min price is 0, so we use log(x+1)\n",
    "    data['visitor_hist_adr_usd_log'] = np.log1p(data['visitor_hist_adr_usd'])\n",
    "    data.drop(columns=['visitor_hist_adr_usd'], inplace=True)\n",
    "\n",
    "    # Transformations of competitor rates\n",
    "    data[\"sum_comp_rate\"] = data[[\"comp1_rate\", \"comp2_rate\", \"comp3_rate\", \"comp4_rate\", \"comp5_rate\", \"comp6_rate\", \"comp7_rate\", \"comp8_rate\"]].sum(axis=1)\n",
    "    data[\"sum_comp_inv\"] = data[[\"comp1_inv\", \"comp2_inv\", \"comp3_inv\", \"comp4_inv\", \"comp5_inv\", \"comp6_inv\", \"comp7_inv\", \"comp8_inv\"]].sum(axis=1)\n",
    "    data[\"median_comp_rate_percent_diff\"] = data[[\"comp1_rate_percent_diff\", \"comp2_rate_percent_diff\", \"comp3_rate_percent_diff\", \"comp4_rate_percent_diff\", \"comp5_rate_percent_diff\", \"comp6_rate_percent_diff\", \"comp7_rate_percent_diff\", \"comp8_rate_percent_diff\"]].dropna().median(axis=1)\n",
    "\n",
    "    # Locational features\n",
    "    data[\"domestic_travel_bool\"] = data[\"prop_country_id\"] == data[\"visitor_location_country_id\"]\n",
    "\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_id',value_col='prop_starrating')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='prop_id',value_col='prop_starrating')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='prop_id',value_col='price_1room_1night_log')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_id',value_col='prop_location_score1')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_id',value_col='prop_location_score2')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_destination_id',value_col='price_usd')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_destination_id',value_col='prop_starrating')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_id',value_col='prop_review_score')\n",
    "    data = calculate_diff_from_group_mean(data=data,group_col='srch_id',value_col='promotion_flag')\n",
    "\n",
    "    # # drop original competitor columns\n",
    "    # for x in range(1, 9):\n",
    "    #     data.drop(columns=[f\"comp{x}_rate\", f\"comp{x}_inv\", f\"comp{x}_rate_percent_diff\"], inplace=True, errors='ignore')\n",
    "\n",
    "    data.drop(columns=['srch_destination_id'], inplace=True, errors='ignore')\n",
    "\n",
    "    for c in categorical_feature:\n",
    "        data[c] = data[c].astype('category')\n",
    "\n",
    "    if type=='train':\n",
    "        data = create_book_feature(data)\n",
    "\n",
    "    logger.debug(\"Feature engineering completed\")\n",
    "    return data"
   ],
   "id": "3ad64ef67cbd402"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = feature_engineering(data=df,type='train')\n",
    "df_test = feature_engineering(data=df_test,type='test')\n"
   ],
   "id": "ae55f4c25b323f5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Split df into training and validation sets based on srch_id ---\n",
    "all_srch_ids = df['srch_id'].unique()\n",
    "train_srch_ids, val_srch_ids = train_test_split(all_srch_ids, test_size=0.05, random_state=42)\n",
    "\n",
    "train_split_df = df[df['srch_id'].isin(train_srch_ids)].copy()\n",
    "val_df = df[df['srch_id'].isin(val_srch_ids)].copy()\n",
    "\n",
    "print(f\"\\nShape of train_split_df: {train_split_df.shape}\")\n",
    "print(f\"Shape of val_df: {val_df.shape}\")\n",
    "print(f\"Number of unique srch_id in train_split_df: {train_split_df['srch_id'].nunique()}\")\n",
    "print(f\"Number of unique srch_id in val_df: {val_df['srch_id'].nunique()}\")\n"
   ],
   "id": "29f3e5c3e1a56198"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['srch_id', 'prop_id', 'booking_bool','click_bool', 'position','gross_bookings_usd','book_feature']]\n",
    "\n",
    "label = 'book_feature'\n",
    "# --- Prepare Training Data ---\n",
    "train_split_df = train_split_df.sort_values('srch_id') # Sort by srch_id\n",
    "X_train = train_split_df[feature_cols]\n",
    "y_train = train_split_df[label]\n",
    "group_train = train_split_df.groupby('srch_id', sort=False).size().to_list()\n",
    "\n",
    "print(f\"\\nNumber of training groups (searches) for actual training: {len(group_train)}\")\n",
    "print(f\"Total training samples for actual training: {sum(group_train)}\")\n",
    "\n",
    "# --- Prepare Validation Data ---\n",
    "val_df = val_df.sort_values('srch_id') # Sort by srch_id\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df[label]\n",
    "group_val = val_df.groupby('srch_id', sort=False).size().to_list()\n",
    "\n",
    "print(f\"\\nNumber of validation groups (searches): {len(group_val)}\")\n",
    "print(f\"Total validation samples: {sum(group_val)}\")\n",
    "\n",
    "# --- Prepare Test Data  ---\n",
    "X_test = df_test[feature_cols]\n",
    "# We need srch_id and prop_id from test_df for final output generation\n",
    "test_ids = df_test[['srch_id', 'prop_id']].copy()"
   ],
   "id": "36916c8e62d5c59b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### resampling\n",
    "# 1. Identify the samples to be oversampled\n",
    "# Unprivileged group = independent hotels (prop_brand_bool == 0)\n",
    "# Positive outcomes = clicked or booked (book_feature > 0)\n",
    "indep_hotel_pos = train_split_df[\n",
    "    (train_split_df['prop_brand_bool'] == 0) & (train_split_df[label] > 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of independent hotels clicked/booked (book_feature > 0): {len(indep_hotel_pos)}\")\n",
    "\n",
    "# 2. Define oversampling factor\n",
    "# This is how many EXTRA copies you want to add.\n",
    "oversample_factor = 0.5\n",
    "\n",
    "# Create the oversampled data\n",
    "n_samples_to_add = int(len(indep_hotel_pos) * oversample_factor)\n",
    "oversampled_data = resample(\n",
    "    indep_hotel_pos,               # DataFrame to sample from\n",
    "    replace=True,                  # Sample with replacement (bootstrap)\n",
    "    n_samples=n_samples_to_add,    # Number of samples to generate\n",
    "    random_state=42                # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Number of samples to add via oversampling: {n_samples_to_add}\")\n",
    "\n",
    "# 3. Create the new resampled training DataFrame\n",
    "train_df_resampled = pd.concat([train_split_df, oversampled_data], ignore_index=True)\n",
    "print(f\"Resampled training data size: {len(train_df_resampled)}\")"
   ],
   "id": "22293ab461c21f3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.sort resample data again\n",
    "train_df_resampled = train_df_resampled.sort_values('srch_id', kind='mergesort') # Use 'mergesort' for stable sort\n",
    "\n",
    "X_train_resampled = train_df_resampled[feature_cols]\n",
    "y_train_resampled = train_df_resampled[label]\n",
    "group_train_resampled = train_df_resampled.groupby('srch_id', sort=False).size().to_list()\n",
    "\n",
    "\n",
    "print(f\"Resampled X_train shape: {X_train_resampled.shape}\")\n",
    "print(f\"Resampled y_train length: {len(y_train_resampled)}\")"
   ],
   "id": "4ba1d5f7fc54ac5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Train LGBMRanker Model\n",
    "print(\"\\nTraining LGBMRanker model...\")\n",
    "\n",
    "ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",  # Core objective for learning to rank\n",
    "    metric=\"ndcg\",           # Evaluation metric (Normalized Discounted Cumulative Gain)\n",
    "    n_estimators=1000,        # Number of boosting rounds\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,           # No limit on depth\n",
    "    num_leaves=62,          # Number of leaves in each tree\n",
    "    importance_type='gain',\n",
    "    label_gain=[0, 1, 5],      # The gain for unbooked (0) is 0, click (1) is 1,book(2) is 5\n",
    "    random_state=42,\n",
    "    n_jobs=-1#,     # Use all available cores\n",
    "    #boosting='dart'\n",
    "    # Add other parameters as needed, e.g., num_leaves, max_depth, reg_alpha, reg_lambda\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)], # Use validation set here\n",
    "    eval_group=[group_train, group_val],          # Group info for validation set\n",
    "    eval_names=['train', 'valid'],                # Names for the eval sets\n",
    "    eval_at=[5, 10],                              # Evaluate NDCG@k\n",
    "    callbacks=[lgb.early_stopping(200)] # Adjusted early stopping\n",
    ")\n",
    "\n",
    "# ranker.fit(\n",
    "#     X_train_resampled,\n",
    "#     y_train_resampled,\n",
    "#     group=group_train_resampled,\n",
    "#     eval_set=[(X_train, y_train), (X_val, y_val)], # Use validation set here\n",
    "#     eval_group=[group_train, group_val],          # Group info for validation set\n",
    "#     eval_names=['train', 'valid'],                # Names for the eval sets\n",
    "#     eval_at=[5, 10],                              # Evaluate NDCG@k\n",
    "#     callbacks=[lgb.early_stopping(200)] # Adjusted early stopping\n",
    "# )\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "print(\"\\nFeature Importances:\")\n",
    "feature_importances = pd.Series(ranker.feature_importances_, index=feature_cols)\n",
    "print(feature_importances.sort_values(ascending=False))"
   ],
   "id": "e318b7b3927ca24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sort the features by importance for plotting\n",
    "sorted_importances = feature_importances.sort_values(ascending=True)\n",
    "\n",
    "# Select the top N features to display for clarity\n",
    "top_n = 20\n",
    "top_importances = sorted_importances.tail(top_n)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x=top_importances.values, y=top_importances.index, palette=\"viridis\")\n",
    "\n",
    "plt.title(f'Top {top_n} Feature Importances (Importance Type: Gain)', fontsize=16)\n",
    "plt.xlabel('Total Gain', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.tight_layout()  # Adjust layout to make sure labels fit\n",
    "\n",
    "plt.savefig(\"../image/lgbm_feature_importance.png\")\n",
    "print(\"Feature importance plot saved as lgbm_feature_importance.png\")\n",
    "\n",
    "plt.close()"
   ],
   "id": "26f21778852beca8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4. Make Predictions on Test Data\n",
    "print(\"\\nPredicting on test data...\")\n",
    "# a NumPy array of scores. Higher scores indicate a higher predicted likelihood of relevance (booking)\n",
    "test_predictions = ranker.predict(X_test)\n",
    "# test_ids = ['srch_id', 'prop_id', 'predicted_score']\n",
    "test_ids['predicted_score'] = test_predictions"
   ],
   "id": "36f2df7e76c0e3b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5. Rank Properties and Generate Output File\n",
    "print(\"Ranking properties and generating output file...\")\n",
    "\n",
    "# Sort properties within each search_id group by the predicted score\n",
    "test_ids_sorted = test_ids.sort_values(['srch_id', 'predicted_score'], ascending=[True, False])\n",
    "\n",
    "# Select only srch_id and prop_id for the final output\n",
    "output_df = test_ids_sorted[['srch_id', 'prop_id']]\n",
    "\n",
    "output_filename = \"LGBMRanker_predict.csv\"\n",
    "output_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nOutput file '{output_filename}' generated successfully.\")\n",
    "print(\"Sample of the output file:\")\n",
    "print(output_df.head(10))"
   ],
   "id": "78f3583718733775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save model\n",
    "model_filename_lgb = r'model/lgbm_ranker_model_biasmitigation.txt'\n",
    "ranker.booster_.save_model(model_filename_lgb)\n",
    "print(f\"save model as LightGBM format: {model_filename_lgb}\")\n",
    "\n",
    "# load model\n",
    "# loaded_ranker_lgb = lgb.Booster(model_file='lgbm_ranker_model.txt')\n",
    "# ranker_sklearn_loaded = lgb.LGBMRanker() # new ranker instance\n",
    "# ranker_sklearn_loaded.booster_ = loaded_ranker_lgb #\n",
    "\n"
   ],
   "id": "f989f884ac60e6ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 1. Get Predictions for the Validation Set ---\n",
    "if 'predicted_score' not in val_df.columns:\n",
    "    val_predictions = ranker.predict(X_val)\n",
    "    val_df_with_preds = val_df.copy()\n",
    "    val_df_with_preds['predicted_score'] = val_predictions\n",
    "else:\n",
    "    val_df_with_preds = val_df.copy()"
   ],
   "id": "f0d348f1fec52465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 2. Demographic Parity on Predicted Scores ---\n",
    "# Separate into groups based on prop_brand_bool\n",
    "independent_hotels = val_df_with_preds[val_df_with_preds['prop_brand_bool'] == 0]\n",
    "chain_hotels = val_df_with_preds[val_df_with_preds['prop_brand_bool'] == 1]\n",
    "\n",
    "avg_score_independent = independent_hotels['predicted_score'].mean()\n",
    "avg_score_chain = chain_hotels['predicted_score'].mean()\n",
    "\n",
    "print(f\"Average predicted score for Independent Hotels (prop_brand_bool=0): {avg_score_independent:.4f}\")\n",
    "print(f\"Average predicted score for Major Chain Hotels (prop_brand_bool=1): {avg_score_chain:.4f}\")\n",
    "\n",
    "if avg_score_chain > avg_score_independent:\n",
    "    print(f\"Chain hotels receive, on average, higher scores by {avg_score_chain - avg_score_independent:.4f}.\")\n",
    "    print(f\"Ratio (Chain/Independent): {avg_score_chain / avg_score_independent:.4f}\")\n",
    "else:\n",
    "    print(f\"Independent hotels receive, on average, higher scores by {avg_score_independent - avg_score_chain:.4f}.\")\n",
    "    print(f\"Ratio (Independent/Chain): {avg_score_independent / avg_score_chain:.4f}\")\n",
    "\n",
    "print(\"Consider also comparing this to the average true relevance ('book_feature') for these groups.\")\n",
    "avg_true_relevance_independent = independent_hotels['book_feature'].mean()\n",
    "avg_true_relevance_chain = chain_hotels['book_feature'].mean()\n",
    "print(f\"Average true relevance for Independent Hotels: {avg_true_relevance_independent:.4f}\")\n",
    "print(f\"Average true relevance for Major Chain Hotels: {avg_true_relevance_chain:.4f}\\n\")\n",
    "\n",
    "pro_click_independent = len(independent_hotels[independent_hotels['book_feature'] == 1])/len(independent_hotels)\n"
   ],
   "id": "dbc9f6ca0de450e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 3. Visualizations ---\n",
    "\n",
    "# Distribution of predicted scores by brand_bool\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=val_df_with_preds, x='predicted_score', hue='prop_brand_bool', kde=True, palette={0: 'blue', 1: 'red'})\n",
    "plt.title('Distribution of Predicted Scores by Hotel Brand Type')\n",
    "plt.xlabel('Predicted Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Hotel Type', labels=['Chain (1)','Independent (0)'])\n",
    "# plt.show()\n",
    "# Save the plot\n",
    "plt.savefig(\"../image/ass2_bias2_after.png\")\n",
    "plt.close()"
   ],
   "id": "afdeec3e43196f80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Ensure 'prop_brand_bool' and 'test_predictions' are aligned and ready\n",
    "# # It's often easiest to work if they are in the same DataFrame for filtering\n",
    "# # but we can also work with them as separate aligned arrays/series.\n",
    "#\n",
    "# # Assuming df_test['prop_brand_bool'] is aligned with test_predictions\n",
    "# prop_brand_status = df_test['prop_brand_bool'].values # Get as numpy array for direct boolean indexing\n",
    "#\n",
    "# # --- Calculate Mean Predicted Score for prop_brand_bool == 0 (Non-Brand) ---\n",
    "# scores_non_brand = test_predictions[prop_brand_status == 0]\n",
    "# mean_score_non_brand = np.mean(scores_non_brand) if scores_non_brand.size > 0 else np.nan\n",
    "#\n",
    "# # --- Calculate Mean Predicted Score for prop_brand_bool == 1 (Brand) ---\n",
    "# scores_brand = test_predictions[prop_brand_status == 1]\n",
    "# mean_score_brand = np.mean(scores_brand) if scores_brand.size > 0 else np.nan\n",
    "#\n",
    "# # --- Print Results ---\n",
    "# print(f\"Mean predicted score for items with prop_brand_bool = 0 (Non-Brand): {mean_score_non_brand:.4f}\")\n",
    "# print(f\"Mean predicted score for items with prop_brand_bool = 1 (Brand):     {mean_score_brand:.4f}\")"
   ],
   "id": "317bdf73984e0dc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
